{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e4a7356",
   "metadata": {},
   "source": [
    "<div style=\"text-align:right\">Update date: Mar 19, 2024</div><br>\n",
    "\n",
    "# Forecasting retail<br>\n",
    "## Production code<br>\n",
    "### Objetive<br>\n",
    "Prepare training, evaluation and execution scripts for the production phase that allow generating sales projections at a store-product level for the next 8 days of a large distributor in the food sector.\n",
    "<br><br>\n",
    "### The general outline of this notebook is as follows:<br>\n",
    "\n",
    "1. Generate data processing functions\n",
    "2. Train models by product\n",
    "3. Evaluate forecasting models\n",
    "4. Run forecasting for each product for the next 8 days<br><br>\n",
    "\n",
    "\n",
    "\n",
    " ### Main work tools<br>\n",
    "\n",
    "\n",
    "|Package|                           Version|\n",
    "|:---------------------------------|--------:|\n",
    "|matplotlib                        |3.8.0|\n",
    "|numpy                             | 1.26.3|\n",
    "|notebook                          |6.5.4|\n",
    "|pandas                            | 2.1.4|\n",
    "|python                            |3.11.7|\n",
    "|sklearn                           |1.2.2|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1f49b6",
   "metadata": {},
   "source": [
    "### Generate data processing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6aef6",
   "metadata": {},
   "source": [
    "The following functions are the result of the work developed in the [data processing notebook to clean](https://github.com/ACCpath/MachineLearning/blob/main/Retail/notebooks/01_forecasting_prepare_data.ipynb) to explore, construct new variables and transform the data obtained from a database with 3 years of historical sales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048be20d",
   "metadata": {},
   "source": [
    "#### Data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a01d825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_mode(df, column):\n",
    "    mode_value = df[column].mode()[0]\n",
    "    df[column] = df[column].fillna(mode_value)\n",
    "    return df\n",
    "\n",
    "def apply_data_quality(x):\n",
    "    temp = x.astype({'month': 'category', 'wday': 'category'})\n",
    "    vars_impute = ['event_name_1']\n",
    "    temp[vars_impute] = temp[vars_impute].fillna('No_event')\n",
    "    temp = (temp.groupby('item_id', group_keys=False)\n",
    "            .apply(lambda x: impute_mode(x, 'sell_price')))\n",
    "    \n",
    "    return temp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317a01a2",
   "metadata": {},
   "source": [
    "#### Generate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "46ffd23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_stock_out(sales, n=5):\n",
    "    zero_sales = pd.Series(np.where(sales==0, 1, 0))\n",
    "    num_zeros = zero_sales.rolling(n).sum()\n",
    "    return np.where(num_zeros==n, 1, 0)\n",
    "\n",
    "def generate_lags(df, variable, num_lags=7):\n",
    "    \"\"\"Generates lagged versions of a specific variable in a DataFrame.\n",
    "    \"\"\"\n",
    "    lags = pd.DataFrame({\n",
    "        f'{variable}_lag_{lag}': df[variable].shift(lag)\n",
    "        for lag in range(1, num_lags + 1)\n",
    "    })\n",
    "    return lags\n",
    "\n",
    "def calculate_mobile_window(df, variable, window_function, num_periods=7):\n",
    "    \"\"\"Calculates the rolling statistics (min, mean, max) for a specific variable\n",
    "    using historical data shifted down in a period for each specified number of periods.\n",
    "    \"\"\"\n",
    "    window_name = window_function.__name__\n",
    "    return pd.DataFrame({\n",
    "        f'{variable}_{window_name}_{roll}': df[variable].shift(1).rolling(roll).apply(window_function)\n",
    "        for roll in range(2, num_periods + 1)\n",
    "    })\n",
    "\n",
    "def generate_variables(x):\n",
    "    x = x.sort_values(['store_id', 'item_id', 'date'])\n",
    "    #Variables Intermittent demand\n",
    "    stock_out_windows = [3, 7, 15]\n",
    "    for window_size in stock_out_windows:\n",
    "        x[f'stock_out_{window_size}'] = (\n",
    "            x.groupby(['store_id', 'item_id'])\n",
    "            .sales\n",
    "            .transform(lambda x: determine_stock_out(x, window_size))\n",
    "        )\n",
    "    \n",
    "    # Lags\n",
    "    lag_periods = {\n",
    "        'sell_price': 7, 'stock_out_3': 1, 'stock_out_7': 1,\n",
    "        'stock_out_15': 1, 'sales': 15\n",
    "    }\n",
    "    lags_dfs = []\n",
    "    for variable, lag_period in lag_periods.items():\n",
    "        lag_df = (\n",
    "            x.groupby(['store_id', 'item_id'])\n",
    "            .apply(lambda x: generate_lags(x, variable, lag_period))\n",
    "            .reset_index()\n",
    "            .set_index('date')\n",
    "        )\n",
    "        lags_dfs.append(lag_df)\n",
    "    lags_dfs = pd.concat(lags_dfs, axis=1)\n",
    "\n",
    "    # Mobile windows\n",
    "    window_functions = [np.min, np.mean, np.max]\n",
    "    mobile_dfs = []\n",
    "\n",
    "    for window_function in window_functions:\n",
    "        mobile_df = (\n",
    "            x.groupby(['store_id', 'item_id'])\n",
    "            .apply(lambda x: calculate_mobile_window(x, 'sales', window_function, 15))\n",
    "            .reset_index()\n",
    "            .set_index('date')\n",
    "        )\n",
    "        mobile_dfs.append(mobile_df)\n",
    "    mobile_dfs = pd.concat(mobile_dfs, axis=1)\n",
    "    # Holidays variable\n",
    "    x['festive'] = np.where(x['event_name_1'] == 'No_event', 0, 1)\n",
    "    \n",
    "    # Combine DataFrames    \n",
    "    x_combined = pd.concat([x, lags_dfs, mobile_dfs], axis=1)\n",
    "\n",
    "    # Remove duplicate columns\n",
    "    x_combined = x_combined.loc[:,~x_combined.columns.duplicated()]\n",
    "    \n",
    "    # Drop NaN values\n",
    "    x_combined.dropna(inplace=True)\n",
    "    \n",
    "    # Remove unnecessary columns\n",
    "    vars_delete = ['sell_price', 'stock_out_3', 'stock_out_7', 'stock_out_15']\n",
    "    x_combined.drop(columns=vars_delete, inplace=True)\n",
    "    \n",
    "    x_combined.insert(loc=0, column='productf',\n",
    "                      value=x_combined.store_id + '_' + x_combined.item_id)   \n",
    "    x_combined = x_combined.drop(columns=['store_id', 'item_id'])\n",
    "    \n",
    "    return x_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f30428b",
   "metadata": {},
   "source": [
    "#### Transform variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b79a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_variables(x, y=None, way='train', project_path='route/to/project'):\n",
    "    x.reset_index(inplace=True)\n",
    "\n",
    "    # Manage encoders and categorical variables\n",
    "    var_cat = ['month', 'wday', 'weekday', 'event_name_1']\n",
    "    encoders = {\n",
    "        'ohe': {'name': 'ohe_retail.pickle', 'vars': var_cat},\n",
    "        'te': {'name': 'te_retail.pickle', 'vars': var_cat}\n",
    "    }\n",
    "\n",
    "    for encoder_type, config in encoders.items():\n",
    "        path = os.path.join(project_path, 'models', config['name'])\n",
    "        if encoder_type == 'ohe' :\n",
    "            encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        else:\n",
    "            encoder = TargetEncoder(min_samples_leaf=100, return_df=False)\n",
    "        \n",
    "        if way == 'train':\n",
    "            if encoder_type == 'te':\n",
    "                y.reset_index(inplace=True, drop=True)\n",
    "                y = y.loc[y.index.isin(x.index)]\n",
    "            encoder.fit(x[config['vars']], y=y if encoder_type == 'te' else None)\n",
    "            \n",
    "            # Save the trained encoder\n",
    "            with open(path, mode='wb') as file:\n",
    "                pickle.dump(encoder, file)\n",
    "        else:\n",
    "            # Load saved encoder\n",
    "            with open(path, mode='rb') as file:\n",
    "                encoder = pickle.load(file)\n",
    "        \n",
    "        # Transform variables\n",
    "        encoded_data = encoder.transform(x[config['vars']])\n",
    "        \n",
    "        # Get the names of the encoded columns\n",
    "        if encoder_type == 'te':\n",
    "            col_names = [f'{var}_encoded' for var in config['vars']]\n",
    "        else:\n",
    "            # Get the names of the binary columns generated by OneHotEncoder\n",
    "            col_names = encoder.get_feature_names_out(input_features=config['vars'])\n",
    "        \n",
    "        # Update \"x\" with hardcoded variables\n",
    "        x_encoded = pd.DataFrame(\n",
    "            encoded_data,\n",
    "            columns=col_names,\n",
    "            index = x.index\n",
    "        )\n",
    "        x = pd.concat([x, x_encoded], axis=1)\n",
    "    \n",
    "    x.drop(columns=var_cat, inplace=True) \n",
    "    x.set_index('date', inplace=True)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6852df6",
   "metadata": {},
   "source": [
    "#### Preselect variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "785415fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preselect_variables(x, y, position_variable_limit=80):\n",
    "    x = x.drop(columns='productf').reset_index(drop=True)\n",
    "    \n",
    "    # Align y with the filtered indices of x\n",
    "    y = y.loc[y.index.isin(x.index)]\n",
    "    \n",
    "    # Calculate mutual information\n",
    "    mutual_info = mutual_info_regression(x, y)\n",
    "    \n",
    "    # Create DataFrame for ranking mutual information\n",
    "    df_ranking = pd.DataFrame({'variable': x.columns, 'importance_mi': mutual_info}) \\\n",
    "                    .sort_values(by='importance_mi', ascending=False) \\\n",
    "                    .reset_index(drop=True)\n",
    "    \n",
    "    # Add ranking based on mutual information\n",
    "    df_ranking['ranking_mi'] = df_ranking.index\n",
    "    \n",
    "    # Select top variables based on mutual information\n",
    "    selected_vars = df_ranking.iloc[:position_variable_limit]['variable']\n",
    "    # Add  Holidays\n",
    "    selected_vars = selected_vars.to_list() + ['festive']\n",
    "    # Select only the top variables in x\n",
    "    x_mi = x[selected_vars].copy()\n",
    "    \n",
    "    return x_mi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4d6682",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8e511c",
   "metadata": {},
   "source": [
    "##### Training\n",
    "After testing with various hyperparameter combinations of the Hist Gradient Boosting Regressor algorithm, its default values provide the lowest error for the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3db07e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_product(x_product, y_product):\n",
    "    \n",
    "    # Select predictor variables\n",
    "    select_vars = x_product.columns[2:].to_list()\n",
    "    \n",
    "    # Define cross validation settings\n",
    "    time_cv = TimeSeriesSplit(5, test_size=8)\n",
    "    \n",
    "    # Define the pipeline estimator and the hyperparameter grid\n",
    "    pipe = Pipeline([('algorithm', HistGradientBoostingRegressor)])\n",
    "    grid = [{'algorithm': [HistGradientBoostingRegressor()]}]\n",
    "    \n",
    "    # Perform random hyperparameter search\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_distributions=grid,\n",
    "        n_iter=1,\n",
    "        cv=time_cv,\n",
    "        scoring='neg_mean_absolute_error', \n",
    "        verbose=0,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    # Train the final model\n",
    "    final_model = random_search.fit(x_product[select_vars], y_product).best_estimator_\n",
    "    \n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec5c0353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_training(df, project_path):\n",
    "    \"\"\"Train models for each product in the dataframe and save them.\n",
    "    \"\"\"\n",
    "    list_models = []\n",
    "    for product in df['productf'].unique():\n",
    "        df_product = df[df['productf'] == product].copy()\n",
    "        x = df_product.drop(columns='sales').copy()\n",
    "        y = df_product['sales'].copy()\n",
    "        x = transform_variables(x=x, y=y, project_path=project_path)\n",
    "        x = preselect_variables(x, y)\n",
    "        model = model_product(x, y)\n",
    "        list_models.append((product, model))\n",
    "    file_models = 'list_models_retail.pickle'\n",
    "    path_models = os.path.join(project_path, 'models', file_models)\n",
    "    with open(path_models, mode='wb') as file:\n",
    "        pickle.dump(list_models, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3b91cd",
   "metadata": {},
   "source": [
    "##### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f8fa5624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_execution(df, project_path):\n",
    "    \"\"\"Run the models trained with the provided data and generate predictions\n",
    "    for the corresponding day.\n",
    "    \"\"\"\n",
    "    # Load the trained models\n",
    "    file_models = 'list_models_retail.pickle'\n",
    "    path_models = os.path.join(project_path, 'models', file_models)\n",
    "    with open(path_models, mode='rb') as file:\n",
    "        list_models = pickle.load(file)\n",
    "    \n",
    "    prediction_df = pd.DataFrame(columns=['date', 'productf', 'sales', 'prediction'])\n",
    "    \n",
    "    # Iterate over each product and its respective model\n",
    "    for product, model in list_models:\n",
    "        \n",
    "        # Filter the dataframe by product\n",
    "        df_product = df[df['productf'] == product].copy()\n",
    "        \n",
    "        # Transform input variables\n",
    "        x = transform_variables(x=df_product.drop(columns='sales'), way='execution',\n",
    "                                project_path=project_path)\n",
    "        # Select variables\n",
    "        x = x[model[0].feature_names_in_]\n",
    "        \n",
    "        # Make predictions and store the results\n",
    "        prediction_df = pd.concat([prediction_df, pd.DataFrame({\n",
    "            'date': df_product.index.values,\n",
    "            'productf': product,\n",
    "            'sales': df_product['sales'],\n",
    "            'prediction': model.predict(x).astype(int)\n",
    "            \n",
    "        })])\n",
    "    # Update negative predictions\n",
    "    prediction_df.loc[(prediction_df['prediction'] < 0), 'prediction'] = 0\n",
    "    # Return only predictions corresponding to the minimum date\n",
    "    return prediction_df.loc[prediction_df.index == prediction_df.index.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "921de3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_recursive_forecast(x, project_path):\n",
    "    \"\"\"Calculate sales prediction for the next 8 days using an iterative approach.\n",
    "    Args:\n",
    "        x(DataFrame): Sales history with file structure \"data_for_production.csv\"\n",
    "        located in the directory: /data/validation\n",
    "    Returns:\n",
    "        DataFrame updated with sales predictions\n",
    "    \"\"\"\n",
    "    for _ in range(8):\n",
    "        step1_df = apply_data_quality(x.copy())\n",
    "        step2_df = generate_variables(step1_df)\n",
    "        \n",
    "        predictions_df =  launch_execution(step2_df, project_path)\n",
    "        predictions_df['store_id'] = predictions_df['productf'].str[:4]\n",
    "        predictions_df['item_id'] = predictions_df['productf'].str[5:]\n",
    "\n",
    "        sales_update_condition = (\n",
    "            x.index.isin(predictions_df['date'])\n",
    "            & x['store_id'].isin(predictions_df['store_id'])\n",
    "            & x['item_id'].isin(predictions_df['item_id'])\n",
    "        )\n",
    "        x.loc[sales_update_condition, 'sales'] = predictions_df['prediction']\n",
    "                                                              \n",
    "        x = x[x.index != x.index.min()]\n",
    "        \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b4a520",
   "metadata": {},
   "source": [
    "### Train models by product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fd752c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load data\n",
    "project_path = '../'\n",
    "file_name = 'work.csv'\n",
    "full_path = os.path.join(project_path, 'data', file_name)\n",
    "df = pd.read_csv(full_path, sep=',', parse_dates=['date'], index_col='date')\n",
    "\n",
    "#Select variables\n",
    "final_vars = [\n",
    "    'store_id',\n",
    "    'item_id',\n",
    "    'event_name_1',\n",
    "    'month',\n",
    "    'sell_price',                      \n",
    "    'wday',\n",
    "    'weekday',\n",
    "    'sales']\n",
    "df = df[final_vars]\n",
    "\n",
    "# Train models\n",
    "step1_df = apply_data_quality(df)\n",
    "step2_df = generate_variables(step1_df)\n",
    "launch_training(step2_df, project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f02453",
   "metadata": {},
   "source": [
    "### Evaluate forecasting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3eef449b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE =  4.8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>productf</th>\n",
       "      <th>sales</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_090</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_120</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_202</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_252</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_288</td>\n",
       "      <td>35</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_329</td>\n",
       "      <td>64</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_555</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_586</td>\n",
       "      <td>76</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_587</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_714</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_090</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_120</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_202</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_252</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_288</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_329</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_555</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_586</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_587</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_714</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date          productf sales prediction\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_090     0          0\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_120    52         49\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_202    20         13\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_252    36         35\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_288    35         24\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_329    64         44\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_555    30         27\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_586    76         62\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_587    29         31\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_714    19         15\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_090     0          0\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_120    16          6\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_202    11         12\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_252     5          6\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_288     3          7\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_329    10          6\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_555     4          2\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_586    10          9\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_587     5         10\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_714    11          8"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load data\n",
    "project_path = '../'\n",
    "file_name = 'validation.csv'\n",
    "full_path = os.path.join(project_path, 'data/validation', file_name)\n",
    "df = pd.read_csv(full_path, sep=',', parse_dates=['date'], index_col='date')\n",
    "\n",
    "#Select variables\n",
    "final_vars = [\n",
    "    'store_id',\n",
    "    'item_id',\n",
    "    'event_name_1',\n",
    "    'month',\n",
    "    'sell_price',                      \n",
    "    'wday',\n",
    "    'weekday',\n",
    "    'sales']\n",
    "df = df[final_vars]\n",
    "\n",
    "#Evaluate models\n",
    "step1_df = apply_data_quality(df)\n",
    "step2_df = generate_variables(step1_df)\n",
    "forecast_1day = launch_execution(step2_df, project_path)\n",
    "\n",
    "print('MAE = ', mean_absolute_error(forecast_1day.sales, forecast_1day.prediction))\n",
    "forecast_1day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d50927",
   "metadata": {},
   "source": [
    "### Run forecasting for each product for the next 8 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a541ae4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>month</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>wday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17/12/2015</th>\n",
       "      <td>CA_3</td>\n",
       "      <td>FOODS_3_090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18/12/2015</th>\n",
       "      <td>CA_3</td>\n",
       "      <td>FOODS_3_090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19/12/2015</th>\n",
       "      <td>CA_3</td>\n",
       "      <td>FOODS_3_090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20/12/2015</th>\n",
       "      <td>CA_3</td>\n",
       "      <td>FOODS_3_090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21/12/2015</th>\n",
       "      <td>CA_3</td>\n",
       "      <td>FOODS_3_090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>Monday</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27/12/2015</th>\n",
       "      <td>CA_4</td>\n",
       "      <td>FOODS_3_714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/12/2015</th>\n",
       "      <td>CA_4</td>\n",
       "      <td>FOODS_3_714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.58</td>\n",
       "      <td>3</td>\n",
       "      <td>Monday</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29/12/2015</th>\n",
       "      <td>CA_4</td>\n",
       "      <td>FOODS_3_714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.58</td>\n",
       "      <td>4</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/12/2015</th>\n",
       "      <td>CA_4</td>\n",
       "      <td>FOODS_3_714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.58</td>\n",
       "      <td>5</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/12/2015</th>\n",
       "      <td>CA_4</td>\n",
       "      <td>FOODS_3_714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.58</td>\n",
       "      <td>6</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           store_id      item_id event_name_1  month  sell_price  wday  \\\n",
       "date                                                                     \n",
       "17/12/2015     CA_3  FOODS_3_090          NaN     12        1.00     6   \n",
       "18/12/2015     CA_3  FOODS_3_090          NaN     12        1.00     7   \n",
       "19/12/2015     CA_3  FOODS_3_090          NaN     12        1.00     1   \n",
       "20/12/2015     CA_3  FOODS_3_090          NaN     12        1.00     2   \n",
       "21/12/2015     CA_3  FOODS_3_090          NaN     12        1.00     3   \n",
       "...             ...          ...          ...    ...         ...   ...   \n",
       "27/12/2015     CA_4  FOODS_3_714          NaN     12        1.58     2   \n",
       "28/12/2015     CA_4  FOODS_3_714          NaN     12        1.58     3   \n",
       "29/12/2015     CA_4  FOODS_3_714          NaN     12        1.58     4   \n",
       "30/12/2015     CA_4  FOODS_3_714          NaN     12        1.58     5   \n",
       "31/12/2015     CA_4  FOODS_3_714          NaN     12        1.58     6   \n",
       "\n",
       "              weekday sales  \n",
       "date                         \n",
       "17/12/2015   Thursday     0  \n",
       "18/12/2015     Friday     1  \n",
       "19/12/2015   Saturday     0  \n",
       "20/12/2015     Sunday     6  \n",
       "21/12/2015     Monday     4  \n",
       "...               ...   ...  \n",
       "27/12/2015     Sunday    16  \n",
       "28/12/2015     Monday    10  \n",
       "29/12/2015    Tuesday    10  \n",
       "30/12/2015  Wednesday    11  \n",
       "31/12/2015   Thursday    10  \n",
       "\n",
       "[300 rows x 8 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load data\n",
    "project_path = '../'\n",
    "file_name = 'data_for_production.csv'\n",
    "full_path = os.path.join(project_path, 'data/validation', file_name)\n",
    "df = pd.read_csv(full_path, sep=';', parse_dates=['date'], index_col='date')\n",
    "\n",
    "#Select variables\n",
    "\n",
    "final_vars = [\n",
    "    'store_id',\n",
    "    'item_id',\n",
    "    'event_name_1',\n",
    "    'month',\n",
    "    'sell_price',                      \n",
    "    'wday',\n",
    "    'weekday',\n",
    "    'sales']\n",
    "df = df[final_vars]\n",
    "\n",
    "#Launch prediction\n",
    "forecast = run_recursive_forecast(df, project_path)\n",
    "forecast.sort_values(by=['store_id', 'item_id'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "328px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
